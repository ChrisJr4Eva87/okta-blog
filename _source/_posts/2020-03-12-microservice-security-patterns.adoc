---
layout: blog_post
title: "Security Patterns for Microservice Architectures"
author: mraible
description: "Are you securing your microservice architectures by hiding them behind a firewall? That works, but there are better ways to do it."
tags: [microservices, security, security patterns, microservice patterns]
tweets:
- ""
- ""
- ""
image:
---
:toc: macro
:page-liquid:
:experimental:

If you attend a lot of Java ecosystem conferences, you'll think that everyone uses microservices. It's a trendy topic, and developers everywhere are interested in learning about them. For a good reason too! Microservice architectures are a technique for delivering code faster.

Chris Richardson is a friend and expert on microservices. He suggests a helpful guideline in a recent blog post:

.Why microservices?
[quote, Chris Richardson, When to use the microservice architecture]]
----
IF
  you are developing a large/complex application
AND
  you need to deliver it rapidly, frequently and reliably
  over a long period of time
THEN
  the Microservice Architecture is often a good choice
----

Chris Richardson also runs https://microservices.io/[microservices.io], which lists several microservice patterns at the bottom. I noticed that "access tokens" is the only item under security.

// In this post, I hope to describe 11 patterns for secure microservice architectures. Many of these may apply to monoliths too.

In the same vein as Chris's listing, the patterns in this post might not be necessary or needed by everyone. For example, if I say to use Paseto tokens instead of JWT when possible, that's going to be difficult for developers that use Okta or other IdPs that don't offer Paseto.

Below are 11 patterns I recommend to secure microservice architectures.

[role="no-title"]
toc::[]

== 1. Be Secure by Design

Secure code is the best code. Secure by design means that you bake security into your software design from the beginning. If you have user input, sanitize the data and remove malicious characters.

As engineers, we're taught early on about the importance of creating well-designed software and architectures. You study it and take pride in it. Design is a natural part of building software.

https://www.manning.com/books/secure-by-design[image:{% asset_path 'blog/microservice-security-patterns/secure-by-design.png' %}[alt=Secure by Design Book,width=150,align=center,role="pull-right w-150px m-x-sm fa-border"]]

Well-known security threats should drive design decisions in security architectures. Reusable techniques and patterns provide solutions for enforcing the necessary authentication, authorization, confidentiality, data integrity, privacy, accountability, and availability, even when the system is under attack.

From the InfoQ Podcast and its https://www.infoq.com/podcasts/web-security-hack-anatomy/[Johnny Xmas on Web Security & the Anatomy of a Hack] episode:

> The OWASP Top 10 really hasn't changed all that much in the last ten years. For example, despite being the number one approach used to educate defensive engineers on how to protect their apps, SQL Injection is still the most common attack. We continue to repeat the same mistakes that have exposed systems for a decade now.

This is why security precautions need to be baked into your architecture.

I like the example from the https://www.manning.com/books/secure-by-design[Secure by Design] book, by Dan Bergh Johnsson, Daniel Deogun, and Daniel Sawano. They show how you can develop a basic `User` object that has a username that's displayed on a page.

[source,java]
----
public class User {
   private final Long id;
   private final String username;

   public User(final Long id, final String username) {
      this.id = id;
      this.username = username;
   }

   // ...
}
----

If you accept any string value for the username, the username could be used for performing XSS attacks. You can fix this with input validation, like the following.

[source,java]
----
import static com.example.xss.ValidationUtils.validateForXSS;
import static org.apache.commons.lang3.Validate.notNull;

public class User {
   private final Long id;
   private final String username;

   public User(final Long id, final String username) {
      notNull(id);
      notNull(username);

      this.id = notNull(id);
      this.username = validateForXSS(username);
   }
}
----

This code is still problematic.

* Developers need to be thinking about security vulnerabilities
* It requires every developer to be a security expert
* It assumes that the person writing the code can think of every potential weakness that might occur now or in the future

A better design is to create a `Username` class that encapsulates all of the security concerns.

[source,java]
----
import static org.apache.commons.lang3.Validate.*;

public class Username {
   private static final int MINIMUM_LENGTH = 4;
   private static final int MAXIMUM_LENGTH = 40;
   private static final String VALID_CHARACTERS = "[A-Za-z0-9_-]+";

   private final String value;

   public Username(final String value) {
      notBlank(value);

      final String trimmed = value.trim();
      inclusiveBetween(MINIMUM_LENGTH,
                       MAXIMUM_LENGTH,
                       trimmed.length());
      matchesPattern(trimmed,
                     VALID_CHARACTERS,
                     "Allowed characters are: %s", VALID_CHARACTERS);
      this.value = trimmed;
   }

   public String value() {
      return value;
   }
}

public class User {
   private final Long id;
   private final Username username;

   public User(final Long id, final Username username) {
      this.id = notNull(id);
      this.username = notNull(username);
   }
}
----

This way, your design makes it easier for developers to write secure code.

Writing and shipping secure code is going to become more and more important as we put more software in robots and embedded devices.

== 2. Scan Dependencies

80% of the code you deploy to production is composed of 3rd party dependencies. Many of the libraries we use to develop software are dependent on other libraries. Transitive dependencies lead to a (sometimes) large chain of dependencies, some of which might have security vulnerabilities.

You can use a scanning program on your source code repository to identify vulnerable dependencies. You should be scanning for vulnerabilities in your primary line of code, in released versions of code, as well as in new code contributions.

If you're a GitHub user, you can use https://dependabot.com/[dependabot] to provide automated updates via pull requests. GitHub also provides https://help.github.com/en/github/managing-security-vulnerabilities/about-security-alerts-for-vulnerable-dependencies[security alerts] you can enable on your repository.

image::{% asset_path 'blog/microservice-security-patterns/github-security-alerts.svg' %}[alt=GitHub Security Alerts,width=400,align=center]

There's also more full-featured solutions, such as https://snyk.io/[Snyk] and https://jfrog.com/xray/[JFrog Xray].

++++
<div style="width: 600px; text-align: center; margin: 0 auto">
  <img src="{% asset_path 'blog/microservice-security-patterns/snyk.png' %}" width="310" alt="Snyk">
  <img src="{% asset_path 'blog/microservice-security-patterns/jfrog-xray.png' %}" width="200" alt="JFrog Xray">
</div>
++++

== 3. Use HTTPS Everywhere

You should use HTTPS everywhere. If you have an HTTP connection, change it to an HTTPS one. Make sure all aspects of your workflow -- from Maven repositories to XSDs -- refer to HTTPS URIs.

HTTPS has an official name: Transport Layer Security (a.k.a., TLS). It's designed to ensure privacy and data integrity between computer applications. https://howhttps.works/[How HTTPS Works] is an excellent site for learning more about HTTPS.

image::{% asset_path 'blog/microservice-security-patterns/how-https-works.png' %}[alt=How HTTPS Works,align=center,width=800]

Let's Encrypt offers free certificates, and you can automate renewing them using its API. From a https://www.infoq.com/news/2020/03/letsencrypt-revokes-certificates/[recent InfoQ article] by https://twitter.com/MaybeSergio[Sergio De Simone]:

> Let's Encrypt launched on April 12, 2016 and somehow transformed the Internet by making a costly and lengthy process, such as using HTTPS through an X.509 certificate, into a straightforward, free, widely available service. Recently, the organization announced it has issued one billion certificates overall since its foundation and it is estimated that Let's Encrypt doubled the Internet's percentage of secure websites.

Let's Encrypt recommends you use **Certbot** to obtain and renew your certificates. Certbot is a free, open-source software tool for automatically using Let's Encrypt certificates on manually-administrated websites to enable HTTPS. Certbot is made by the Electronic Frontier Foundation (EFF).

https://certbot.eff.org/[image:{% asset_path 'blog/microservice-security-patterns/certbot-logo.svg' %}[alt=Certbots,role="pull-right w-200 m-x-m",width=200]]
The https://certbot.eff.org/[Certbot] site let's you choose your web server and system, then provides the instructions for automating certificate generation and renewal. For example, https://certbot.eff.org/lets-encrypt/ubuntubionic-nginx[here's instructions for Ubuntu with Nginx].

To use a certificate with Spring Boot, you just need some configuration.

[source,yaml]
.src/main/resources/application.yml
----
server:
  ssl:
    key-store: classpath:keystore.p12
    key-store-password: password
    key-store-type: pkcs12
    key-alias: tomcat
    key-password: password
  port: 8443
----

_Storing passwords and secrets in configuration files is a bad idea. I'll show you how to encrypt keys like this below._

You also might want to force HTTPS. You can see how to do that in https://developer.okta.com/blog/2018/07/30/10-ways-to-secure-spring-boot#1-use-https-in-production[10 Excellent Ways to Secure Your Spring Boot Application]. Often, forcing HTTPS involves using an **HTTP Strict-Transport-Security** response header (abbreviated as `HSTS`) to tell browsers that a website should only be accessed using HTTPS.

You might ask? "Why do we need HTTPS _inside_ our network?"

This is an excellent question. It's good to protect transmitted data because there may be threats from inside your network.

Johnny Xmas describes how a web attack typically happens in a https://www.infoq.com/podcasts/web-security-hack-anatomy/[recent InfoQ Podcast]. Phishing and guessing people's credentials are incredibly effective techniques. In both cases, the attacker can gain access to an in-network machine (with administrative rights) and wreak havoc.

TIP: To see how to set up your Spring-based microservice architecture to use HTTPS locally, see https://developer.okta.com/blog/2019/03/07/spring-microservices-https-oauth2[Secure Service-to-Service Spring Microservices with HTTPS and OAuth 2.0].

=== Secure GraphQL APIs

GraphQL uses HTTP, so you don't have to do much from a security perspective. The biggest thing you'll need to do is keep your GraphQL implementation up-to-date. GraphQL relies on making POST requests for everything. The server you use will be responsible for input sanitization.

If you'd like to connect to a https://developer.okta.com/blog/2019/12/05/react-graphql-integration-guide[GraphQL server with OAuth 2.0 and React], you just need to pass an `Authorization` header.

TIP: Apollo is a platform for building a data graph, and Apollo Client has implementations for https://www.apollographql.com/docs/react/[React] and https://www.apollographql.com/docs/angular/[Angular], among others.

[source,js]
----
const clientParam = { uri: '/graphql' };
let myAuth = this.props && this.props.auth;
if (myAuth) {
  clientParam.request = async (operation) => {
    let token = await myAuth.getAccessToken();
    operation.setContext({ headers: { authorization: token ? `Bearer ${token}` : '' } });
  }
}
const client = new ApolloClient(clientParam);
----

Configuring a secure ApolloClient https://developer.okta.com/blog/2018/11/30/web-app-with-express-angular-graphql[looks similar for Angular].

[source,ts]
----
export function createApollo(httpLink: HttpLink, oktaAuth: OktaAuthService) {
  const http = httpLink.create({ uri });

  const auth = setContext((_, { headers }) => {
    return oktaAuth.getAccessToken().then(token => {
      return token ? { headers: { Authorization: `Bearer ${token}` } } : {};
    });
  });

  return {
    link: auth.concat(http),
    cache: new InMemoryCache()
  };
}
----

On the server, whatever you use to secure your REST API endpoints can be used to secure GraphQL.

=== Secure RSocket Endpoints

RSocket is a next-generation, reactive, layer 5 application communication protocol for building today's modern cloud-native and microservice applications.

What does all that mean? It means RSocket has reactive semantics built-in, so it can communicate backpressure to clients and provide more reliable communications. The https://rsocket.io/[RSocket website] says implementations are available for Java, JavaScript, Go, .NET, C++, and Kotlin.

TIP: https://docs.spring.io/spring-security/site/docs/5.3.0.RELEASE/reference/html5/#rsocket[Spring Security 5.3.0 has full support for securing RSocket applications].

To learn more about RSocket, I recommend reading https://spring.io/blog/2020/03/02/getting-started-with-rsocket-spring-boot-server[Getting Started With RSocket: Spring Boot Server].

== 4. Use Access and Identity Tokens

OAuth 2.0 has provided delegated authorization since 2012. OpenID Connect added federated identity on top of OAuth 2.0 in 2014. Together, they offer a standard spec you can write code against and have confidence that it will work across IdPs (Identity Providers).

The spec also allows you to look up the identity of the user by sending an access token to the `/userinfo` endpoint. The URI for this endpoint can be looked up using OIDC discovery, providing a standard way to obtain a user's identity.

image::{% asset_path 'blog/microservice-security-patterns/openid-connect.png' %}[alt=OpenID Connect,width=800,align=center]

If you're communicating between microservices, you can use OAuth 2.0's client credentials flow to implement https://developer.okta.com/blog/2018/04/02/client-creds-with-spring-boot[secure server-to-server communication]. In the diagram below, the `API Client` is one server, and the `API Server` is another.

image::{% asset_path 'blog/microservice-security-patterns/client-credentials.png' %}[alt=Client Credentials,width=800,align=center]

=== Authorization Servers: One or Many?

If you are using OAuth 2.0 to secure your service, you're using an authorization server. The typical setup is a many-to-one relationship, where you have many microservices talking to one authorization server.

image::{% asset_path 'blog/microservice-security-patterns/auth-server-one-to-many.png' %}[alt=Auth Server: One-to-Many,width=600,align=center]

The pros of this approach:

* Services can use access tokens to talk to any other internal services (since they were all minted by the same authorization server)
* Single place to look for all scope and permission definitions
* Easier to manage for developers and security people
* Faster (less chatty)

The cons:

* Opens you up to the possibility of rogue services causing problems with their tokens
* If one service's token is compromised, all services are at risk
* Vague security boundaries

The other, more security, alternative is that every microservice is bound to its own authorization server.

image::{% asset_path 'blog/microservice-security-patterns/auth-server-many-to-many.png' %}[alt=Auth Server: Many-to-Many,width=600,align=center]

This architecture allows you to have clearly defined security boundaries. However, it's slower because it's more chatty, and it's harder to manage.

My recommendation: use a one-to-many relationship until you have a plan and documentation to support a many-to-many.

=== Use Paseto Tokens Over JWT

PASETO stands for **p**latform-**a**gnostic **se**curity **to**kens. Paseto is everything you love about JOSE (JWT, JWE, JWS) without any of the many design deficits that plague the JOSE standards.

My colleagues Randall Degges and Brian Demers wrote up some informative posts on Paseto.

* https://developer.okta.com/blog/2019/10/17/a-thorough-introduction-to-paseto[A Thorough Introduction to PASETO]
* https://developer.okta.com/blog/2020/02/14/paseto-security-tokens-java[Create and Verify PASETO Tokens in Java]

Long story, short: using Paseto tokens isn't as easy as it sounds. If you want to write your own security, it is possible. But if you're going to use a well-known cloud provider, chances are it doesn't support the Paseto standard (yet).

== 5. Encrypt and Protect Secrets

When developing microservices that talk to authorization servers and other services, they likely have secrets that they use for communication. These secrets might be an API key, or a client secret, or credentials for basic authentication.

The #1 rule for secrets is **don't check them into source control**. Even if you're developing code in a private repository, it's a nasty habit, and if you're working on production code, it's likely to cause trouble.

The first step to being more secure with secrets is to store them in environment variables. But this is only the beginning. You should do your best to encrypt your secrets.

In the Java world, I'm most familiar with https://www.vaultproject.io/[HashiCorp Vault] and https://spring.io/projects/spring-vault[Spring Vault].

My co-worker https://developer.okta.com/blog/2019/07/25/the-hardest-thing-about-data-encryption#data-encryption-key-management-solutions[Randall is a fan of Amazon KMS].

image::{% asset_path 'blog/the-hardest-thing-about-data-encryption/symmetric-encryption-best-practices.png' %}[alt=Symmetric Encryption Best Practices,width=800,align=center]

In short, the way it works is:

- You generate a master key using KMS
- Each time you want to encrypt data, you ask AWS to generate a new _data key_ for you. A _data key_ is a unique encryption key generated for each piece of data you need to encrypt.
- You then encrypt your data using the _data key_
- Amazon will then encrypt your _data key_ using the master key
- You will then merge the encrypted _data key_ with the encrypted data to create an _encrypted message_. The _encrypted message_ is your final output, what you would store as a file or in a database somewhere.

The reason this is so convenient is that you never need to worry about keeping keys safeguarded -- the keys required to decrypt any data are always unique and safe.

== 6. Verify Security with Delivery Pipelines

Dependency and container scanning should be part of your source control monitoring system, but you should also perform tests when executing your CI (continuous integration) and CD (continuous delivery) pipelines.

Atlassian has an informative blog post titled https://www.atlassian.com/continuous-delivery/principles/devsecops[DevSecOps: Injecting Security into CD Pipelines].

NOTE: DevSecOps is the term many recommend instead of DevOps to emphasize the need to build security into DevOps initiatives. I just wish it rolled off the tongue a little easier. 😉

Atlassian's post recommends using security unit tests, static analysis security testing (SAST), and dynamic analysis security testing (DAST).

Your code delivery pipeline can automate these security checks, but it'll likely take some time to setup.

To learn about a more "Continuous Hacking" approach to software delivery, https://thenewstack.io/beyond-ci-cd-how-continuous-hacking-of-docker-containers-and-pipeline-driven-security-keeps-ygrene-secure/[this article from Zach Arnold and Austin Adams] has some useful tips.

* Create a whitelist of Docker base image to check against at build time
* Ensure you're pulling cryptographically signed base images
* Sign the metadata of a pushed image cryptographically so it can be checked later
* In your containers, only use Linux distributions that verify the integrity of the package using the package manager's security features
* When pulling third-party dependencies manually, only allow HTTPS and ensure checksums are validated
* Don’t allow images to be built whose `Dockerfile` specifies a sensitive host path as a volume mount

But what about the code? They use automation to analyze it too:

* Run static code analysis on the codebase for known code-level security vulnerabilities
* Run automated dependency checkers to make sure you're using the last, most secure version of your dependencies
* Spin up your service, point automated penetration bots at the running containers and see what happens

For a list of code scanners, see https://www.owasp.org/index.php/Source_Code_Analysis_Tools[OWASP's Source Code Analysis Tools].

== 7. Slow Down Attackers

If someone tries to attack your APIs with hundreds of gigs username/password combinations, it could take a while for them to authenticate successfully. If you can detect this attack and slow down your service, it's likely the attacker will go away. It's simply not worth their time.

You can implement rate-limiting in your code (often with an open-source library) or your API Gateway. I'm sure there are other options, but these will likely be the most straightforward to implement.

Most SaaS APIs use rate-limiting to prevent customer abuse. We at Okta have https://developer.okta.com/docs/reference/rate-limits/[API rate limits as well as email rate limits] to help protect against denial-of-service attacks.

== 8. Use Docker Rootless Mode

https://hub.packtpub.com/docker-19-03-introduces-an-experimental-rootless-docker-mode-that-helps-mitigate-vulnerabilities-by-hardening-the-docker-daemon/[Docker 19.03 introduced a rootless mode]. This feature is designed to help reduce the security footprint of the Docker daemon and expose Docker capabilities to systems where users cannot gain root privileges.

If you're running Docker daemons in production, this is definitely something you should look into. However, if you're letting Kubernetes run your Docker containers, you'll need to configure it the `runAsUser` in your `PodSecurityPolicy`.

== 9. Use Time Based Security

Another tip I got from Johnny Xmas on the InfoQ podcast was to use time-based security. https://twitter.com/winnschwartau[Winn Schwartau] wrote a well-known https://winnschwartau.com/books/[Time Based Security book].

The idea behind time-based security is that your system is never fully secure—someone will break-in. Preventing intruders is only one part of securing a system; detection and reaction are essential too.

Use multi-factor authentication to slow down intruders, but also to help detect when someone with elevated privilege authenticates. If you have something like a domain controller that controls network traffic, send an alert to your network administrator team whenever there's a successful login.

This is just one example of trying to detect anomalies and react to them quickly.

// I'm sure there's more to this, I haven't read the book.

== 10. Scan Docker and Kubernetes Configuration for Vulnerabilities

Docker containers are very popular in microservice architectures. Our friends at Snyk published https://snyk.io/blog/10-docker-image-security-best-practices/[10 Docker Image Security Best Practices]. It repeats some of the things I already mentioned, but I'll summarize them here anyway.

1. Prefer minimal base images
2. Use the `USER` directive to make sure the least privileged is used
3. Sign and verify images to mitigate MITM attacks
4. Find, fix, and monitor for open source vulnerabilities (Snyk offers a way to scan and monitor your Docker images too)
5. Don't leak sensitive information to Docker images
6. Use fixed tags for immutability
7. Use `COPY` instead of `ADD`
8. Use metadata labels like `maintainer` and `securitytxt`
9. Use multi-stage builds for small and secure images
10. Use a linter like https://github.com/hadolint/hadolint[hadolint]

You might also find https://resources.whitesourcesoftware.com/blog-whitesource/top-5-docker-vulnerabilities[Top 5 Docker Vulnerabilities You Should Know] from WhiteSource useful.

You should also scan your Kubernetes configuration for vulnerabilities, but there's much more than than, so I'll cover K8s security in the next section.

== 11. Know Your Cloud and Cluster Security

If you're managing your production clusters and clouds, you're probably aware of https://kubernetes.io/docs/concepts/security/#the-4c-s-of-cloud-native-security[the 4C's of Cloud Native Security].

image::{% asset_path 'blog/microservice-security-patterns/4c-cloud-native-security.png' %}[alt=The 4C's of Cloud Native Security,width=700,align=center]

Each one of the 4C's depend on the security of the squares in which they fit. It is nearly impossible to safeguard against poor security standards in Cloud, Containers, and Code by only addressing security at the code level. However, when these areas are dealt with appropriately, then adding security to your code augments an already strong base.

The Kubernetes blog has a detailed post from https://twitter.com/sublimino[Andrew Martin] titled https://kubernetes.io/blog/2018/07/18/11-ways-not-to-get-hacked/[11 Ways (Not) to Get Hacked]. Andrew offers these tips to harden your clusters and increase their resilience if compromised.

1. Use TLS Everywhere
2. Enable RBAC with Least Privilege, Disable ABAC, and use Audit Logging
3. Use a Third-Party Auth provider (like Google, GitHub - _or Okta!_)
4. Separate and Firewall your etcd Cluster
5. Rotate Encryption Keys
6. Use Linux Security Features and a restricted https://gist.github.com/tallclair/11981031b6bfa829bb1fb9dcb7e026b0[`PodSecurityPolicy`]
7. Statically Analyse YAML
8. Run Containers as a Non-Root User
9. Use Network Policies (to limit traffic between pods)
10. Scan Images and Run IDS (Intrusion Detection System)
11. Run a Service Mesh

This blog post is from July 2018, but not a whole lot has changed. I do think there's been a fair amount of hype around service meshes since 2018.

Running a service mesh like Istio _might_ allow you to offload your security to a "shared, battle-tested set of libraries." Still, I don't think it's "simplified the deployment of the next generation of network security" like the blog post says it could.

== Learn More About Microservices and Web Security

I hope these security patterns have helped you become a more security-conscious developer. It's interesting to me that only half of my list pertains to developers that write code on a day-to-day basis.

1. Be Secure by Design
2. Scan Dependencies
3. Use HTTPS Everywhere
4. Use Access and Identity Tokens
5. Encrypt and Protect Secrets

The rest of them seem to apply to DevOps people, or rather DevSecOps.

[start=6]
6. Verify Security with Delivery Pipelines
7. Slow Down Attackers
8. Use Docker Rootless Mode
9. Use Time Based Security
10. Scan Docker and Kubernetes Configuration for Vulnerabilities
11. Know Your Cloud and Cluster Security

Since all of these patterns are important considerations, you should make sure to keep a close relationship between your developer and DevSecOps teams. In fact, if you're doing microservices right, these people aren't on separate teams! They're on the same product team that owns the microservice from concept to production.

Looking for more? We have a few microservice and security-focused blogs I think you'll like:

* https://developer.okta.com/blog/2019/05/22/java-microservices-spring-boot-spring-cloud[Java Microservices with Spring Boot and Spring Cloud]
* https://developer.okta.com/blog/2019/03/21/build-secure-microservices-with-aspnet-core[Build Secure Microservices with AWS Lambda and ASP.NET Core]
* https://developer.okta.com/blog/2020/02/05/node-microservices-zero-to-hero[Node Microservices: From Zero to Hero]
* https://developer.okta.com/blog/2019/07/25/the-hardest-thing-about-data-encryption[The Hardest Thing About Data Encryption]
* https://developer.okta.com/blog/2019/10/23/dangers-of-self-signed-certs[The Dangers of Self-Signed Certificates]

We also wrote a book! https://developer.okta.com/books/api-security/[API Security] is a guide to building and securing APIs from the developer team at Okta.

If you liked this post and want notifications when we post others, please https://twitter.com/oktadev[follow @oktadev on Twitter]. We also have a https://youtube.com/c/oktadev[YouTube channel] you might enjoy. As always, please leave a comment below if you have any questions.
